#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GAM æ¡†æ¶ + LongMemEval æ•°æ®é›†æµ‹è¯•æ–‡ä»¶

ç»“åˆ run_generation.py çš„æ•°æ®å¤„ç†é€»è¾‘å’Œ GAM æ¡†æ¶ï¼Œæµ‹è¯•åœ¨é•¿æœŸè®°å¿†è¯„ä¼°æ•°æ®ä¸Šçš„æ•ˆæœã€‚
"""

import sys
import os
import re
import json
from typing import Any, Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from gam import (
    MemoryAgent,
    ResearchAgent,
    VLLMGenerator,
    InMemoryMemoryStore,
    InMemoryPageStore,
    IndexRetriever,
    BM25Retriever,
    DenseRetriever,
    VLLMGeneratorConfig,
    IndexRetrieverConfig,
    BM25RetrieverConfig,
    DenseRetrieverConfig,
)

# ========== æ•°æ®åŠ è½½ï¼šå€Ÿé‰´è‡ª run_generation.py ==========

def load_longmemeval(json_path: str) -> List[Dict[str, Any]]:
    """Load LongMemEval JSON and return the list of samples."""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except:
        # å¦‚æœæ˜¯ JSONL æ ¼å¼
        data = []
        with open(json_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line.strip()))
    return data

def build_session_chunks_for_sample(sample: Dict[str, Any]) -> List[str]:
    """
    å°† LongMemEval çš„å¯¹è¯æ•°æ®è½¬æ¢ä¸º session æ ¼å¼
    æŒ‰ç…§æ—¶é—´æ®µå’Œ session_id ç»„ç»‡å¯¹è¯ï¼ŒåŒ…å« Current Date ä¿¡æ¯
    """
    sessions = []
    
    # è·å–æ‰€æœ‰å¯¹è¯æ•°æ®
    haystack_dates = sample.get("haystack_dates", [])
    haystack_session_ids = sample.get("haystack_session_ids", [])
    haystack_sessions = sample.get("haystack_sessions", [])
    
    # æŒ‰æ—¶é—´é¡ºåºç»„ç»‡å¯¹è¯
    for i, (date, session_id, session_content) in enumerate(zip(haystack_dates, haystack_session_ids, haystack_sessions)):
        # æ„å»º session æ–‡æœ¬
        session_text = f"=== SESSION {i+1} - Date: {date} - Session ID: {session_id} ===\n"
        session_text += f"Current Date: {date}\n"
        session_text += "\n"
        
        # æ·»åŠ å¯¹è¯å†…å®¹
        for turn in session_content:
            role = turn.get("role", "unknown")
            content = turn.get("content", "")
            session_text += f"{role}: {content}\n"
        
        sessions.append(session_text.strip())
    
    return sessions

def collect_qa_items_for_sample(sample: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä» LongMemEval æ ·æœ¬ä¸­æå– QA ä¿¡æ¯"""
    qas = []
    question_id = sample.get("question_id", "")
    question_type = sample.get("question_type", "unknown")
    
    qas.append({
        "question_id": question_id,
        "question": sample.get("question"),
        "answer": sample.get("answer"),
        "question_type": question_type,
        "question_date": sample.get("question_date"),
        "answer_session_ids": sample.get("answer_session_ids", []),
    })
    return qas

# ========== Prompt è®¾è®¡ï¼šå€Ÿé‰´è‡ª run_generation.py ==========

def safe_json_extract(candidate: Any) -> Optional[Dict[str, Any]]:
    """Try to parse a model's output (string or dict) into dict. Return None if fail."""
    if isinstance(candidate, dict):
        return candidate
    if not isinstance(candidate, str):
        return None
    s = candidate.strip()
    l = s.find('{')
    r = s.rfind('}')
    if l == -1 or r == -1 or r <= l:
        return None
    try:
        return json.loads(s[l:r+1])
    except Exception:
        return None

def make_memory_only_prompt(memory_obj: Any, question: str, question_date: str) -> str:
    """åŸºäºè®°å¿†çŠ¶æ€å›ç­”é—®é¢˜çš„ promptï¼šå€Ÿé‰´è‡ª run_generation.py"""
    mem_str = json.dumps(memory_obj, ensure_ascii=False, indent=2) if isinstance(memory_obj, dict) else str(memory_obj)
    return f"""
I will give you several history chats between you and a user. Please answer the question based on the relevant chat history.

MEMORY STATE:
{mem_str}

Current Date: {question_date}
Question: {question}
Answer:
"""

def make_summary_prompt(summary: str, question: str, question_date: str) -> str:
    """åŸºäºç ”ç©¶æ‘˜è¦å›ç­”é—®é¢˜çš„ promptï¼šå€Ÿé‰´è‡ª run_generation.py"""
    return f"""
I will give you several history chats between you and a user. Please answer the question based on the relevant chat history.

RESEARCH SUMMARY:
{summary}

Current Date: {question_date}
Question: {question}
Answer:
"""

def answer_with_summary(summary: str, question: str, question_date: str, generator) -> str:
    """åŸºäºç ”ç©¶æ‘˜è¦å›ç­”é—®é¢˜"""
    prompt = make_summary_prompt(summary, question, question_date)
    raw = generator.generate_single(prompt=prompt)
    return raw.get("text", "").strip()

def answer_with_memory(final_memory: Dict[str, Any], question: str, question_date: str, generator) -> str:
    """åŸºäºè®°å¿†çŠ¶æ€å›ç­”é—®é¢˜"""
    prompt = make_memory_only_prompt(final_memory, question, question_date)
    raw = generator.generate_single(prompt=prompt)
    return raw.get("text", "").strip()

# ========== æ ¸å¿ƒå¤„ç†é€»è¾‘ ==========

def process_sample(sample: Dict[str, Any], sample_index: int, outdir: str):
    """
    ä½¿ç”¨ GAM æ¡†æ¶å¤„ç†å•ä¸ªæ ·æœ¬ã€‚
    
    æµç¨‹ï¼š
    1. ä½¿ç”¨ MemoryAgent æ„å»ºè®°å¿†
    2. ä½¿ç”¨ ResearchAgent è¿›è¡Œæ·±åº¦ç ”ç©¶
    3. åŸºäºç ”ç©¶ç»“æœè¿›è¡Œé—®ç­”
    """
    question_id = sample.get("question_id", f"sample_{sample_index}")
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ ·æœ¬ #{sample_index}: {question_id}")
    print(f"{'='*60}")
    
    try:
        # 1. æ„å»ºä¼šè¯å—
        session_chunks = build_session_chunks_for_sample(sample)
        print(f"ä¼šè¯æ•°: {len(session_chunks)}")
        if session_chunks:
            print(f"ç¬¬ä¸€ä¸ªä¼šè¯é¢„è§ˆ:\n{session_chunks[0][:400]}...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        sample_results_dir = os.path.join(outdir, question_id)
        os.makedirs(sample_results_dir, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {sample_results_dir}")
        
        # 2. åˆ›å»ºå…±äº«å­˜å‚¨
        memory_store = InMemoryMemoryStore(dir_path=sample_results_dir)
        page_store = InMemoryPageStore(dir_path=sample_results_dir)
        
        # 3. åˆ›å»º Generator
        print(f"\næ­¥éª¤ 1: åˆ›å»º Generator")
        generator_config = VLLMGeneratorConfig(
            model_name="qwen2.5-14b-instruct",
            api_key="empty",
            base_url="http://localhost:8000/v1",
            temperature=0.3,
            max_tokens=2048
        )
        generator = VLLMGenerator(generator_config.__dict__)
        print(f"[OK] Generator åˆ›å»ºå®Œæˆ")
        
        # 4. ä½¿ç”¨ MemoryAgent æ„å»ºè®°å¿†ï¼ˆå°†æ¯ä¸ª session ä½œä¸ºä¸€æ¡æ¶ˆæ¯ï¼‰
        print(f"\næ­¥éª¤ 2: ä½¿ç”¨ MemoryAgent æ„å»ºè®°å¿†")
        memory_agent = MemoryAgent(
            memory_store=memory_store,
            page_store=page_store,
            generator=generator
        )
        
        for i, session_chunk in enumerate(session_chunks, 1):
            print(f"  å¤„ç†ä¼šè¯ {i}/{len(session_chunks)}...")
            memory_update = memory_agent.memorize(session_chunk)
        
        # æŸ¥çœ‹æ„å»ºçš„è®°å¿†
        final_state = memory_store.load()
        print(f"[OK] è®°å¿†æ„å»ºå®Œæˆï¼å…± {len(final_state.abstracts)} æ¡è®°å¿†æ‘˜è¦")
        
        # æ˜¾ç¤ºè®°å¿†æ‘˜è¦
        print("\nğŸ“š è®°å¿†æ‘˜è¦:")
        for i, abstract in enumerate(final_state.abstracts, 1):
            print(f"  {i}. {abstract[:100]}...")
        
        # ä¿å­˜è®°å¿†çŠ¶æ€
        memory_state_file = os.path.join(sample_results_dir, "memory_state.json")
        with open(memory_state_file, 'w', encoding='utf-8') as f:
            json.dump(final_state.model_dump(), f, ensure_ascii=False, indent=2)
        print(f"[OK] è®°å¿†çŠ¶æ€å·²ä¿å­˜: {memory_state_file}")
        
        # 5. åˆ›å»ºæ£€ç´¢å™¨
        print(f"\næ­¥éª¤ 3: åˆ›å»ºæ£€ç´¢å™¨")
        retrievers = {}
        
        # ç´¢å¼•æ£€ç´¢å™¨
        try:
            index_config = IndexRetrieverConfig(
                index_dir=os.path.join(sample_results_dir, "page_index")
            )
            index_retriever = IndexRetriever(index_config.__dict__)
            index_retriever.build(page_store)
            retrievers["page_index"] = index_retriever
            print(f"[OK] ç´¢å¼•æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"[WARN] ç´¢å¼•æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}")
        
        # BM25 æ£€ç´¢å™¨
        try:
            bm25_config = BM25RetrieverConfig(
                index_dir=os.path.join(sample_results_dir, "bm25_index"),
                threads=4
            )
            bm25_retriever = BM25Retriever(bm25_config.__dict__)
            bm25_retriever.build(page_store)
            retrievers["keyword"] = bm25_retriever
            print(f"[OK] BM25 æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"[WARN] BM25 æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}")
        
        # Dense æ£€ç´¢å™¨
        try:
            dense_config = DenseRetrieverConfig(
                index_dir=os.path.join(sample_results_dir, "dense_index"),
                model_name="/share/project/bingyu/models/bge-base-en-v1.5",
                devices=["cuda:0"]
            )
            dense_retriever = DenseRetriever(dense_config.__dict__)
            dense_retriever.build(page_store)
            retrievers["vector"] = dense_retriever
            print(f"[OK] Dense æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"[WARN] Dense æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}")
        
        print(f"[INFO] æˆåŠŸåˆ›å»º {len(retrievers)} ä¸ªæ£€ç´¢å™¨")
        
        # 6. åˆ›å»º ResearchAgent
        print(f"\næ­¥éª¤ 4: åˆ›å»º ResearchAgent")
        research_agent = ResearchAgent(
            page_store=page_store,
            memory_store=memory_store,
            retrievers=retrievers,
            generator=generator,
            max_iters=3
        )
        print(f"[OK] ResearchAgent åˆ›å»ºå®Œæˆ")
        
        # 7. è¿›è¡Œé—®ç­”
        print(f"\næ­¥éª¤ 5: è¿›è¡Œé—®ç­”")
        qas = collect_qa_items_for_sample(sample)
        print(f"å…±æœ‰ {len(qas)} ä¸ªé—®é¢˜éœ€è¦å›ç­”")
        
        # å°†è®°å¿†è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        final_memory_str = json.dumps(final_state.model_dump(), ensure_ascii=False, indent=2)
        
        qa_results = []
        
        for i, qi in enumerate(qas, 1):
            q = qi.get("question") or ""
            gold = qi.get("answer")
            question_type = qi.get("question_type")
            question_date = qi.get("question_date")
            answer_session_ids = qi.get("answer_session_ids", [])
            
            print(f"\n--- é—®é¢˜ {i}/{len(qas)} ---")
            print(f"é—®é¢˜: {q}")
            print(f"æ ‡å‡†ç­”æ¡ˆ: {gold}")
            print(f"é—®é¢˜ç±»å‹: {question_type}")
            print(f"é—®é¢˜æ—¥æœŸ: {question_date}")
            print(f"ç­”æ¡ˆä¼šè¯ID: {answer_session_ids}")
            
            try:
                # ä½¿ç”¨ ResearchAgent è¿›è¡Œç ”ç©¶
                print("æ­£åœ¨è¿›è¡Œæ·±åº¦ç ”ç©¶...")
                result = research_agent.research(q)
                research_summary = result.integrated_memory
                print(f"[OK] ç ”ç©¶å®Œæˆï¼è¿­ä»£æ¬¡æ•°: {len(result.raw_memory.get('iterations', []))}")
                print(f"ç ”ç©¶æ‘˜è¦: {research_summary[:200]}...")
                
                # ä¿å­˜ç ”ç©¶è½¨è¿¹
                research_trace = {
                    "question": q,
                    "raw_memory": result.raw_memory,
                    "integrated_memory": result.integrated_memory,
                    "iterations": result.raw_memory.get("iterations", []),
                    "search_plans": result.raw_memory.get("search_plans", []),
                    "reflections": result.raw_memory.get("reflections", [])
                }
                
                # ä¿å­˜å•ä¸ªé—®é¢˜çš„ç ”ç©¶è½¨è¿¹
                trace_file = os.path.join(sample_results_dir, f"research_trace_q{i}.json")
                with open(trace_file, 'w', encoding='utf-8') as f:
                    json.dump(research_trace, f, ensure_ascii=False, indent=2)
                print(f"[INFO] ç ”ç©¶è½¨è¿¹å·²ä¿å­˜: {trace_file}")
                
                # åŸºäºç ”ç©¶ç»“æœç”Ÿæˆç­”æ¡ˆ
                print("ç”Ÿæˆç­”æ¡ˆ...")
                summary_answer = answer_with_summary(research_summary, q, question_date, generator)
                memory_answer = answer_with_memory(final_memory_str, q, question_date, generator)
                
                print(f"åŸºäºç ”ç©¶çš„ç­”æ¡ˆ: {summary_answer}")
                print(f"åŸºäºè®°å¿†çš„ç­”æ¡ˆ: {memory_answer}")
                
                qa_result = {
                    "question_id": qi.get("question_id"),
                    "question": q,
                    "gold_answer": gold,
                    "question_type": question_type,
                    "question_date": question_date,
                    "answer_session_ids": answer_session_ids,
                    "research_summary": research_summary,
                    "summary_answer": summary_answer,
                    "memory_answer": memory_answer,
                    "iterations": len(result.raw_memory.get("iterations", [])),
                    "research_trace_file": trace_file
                }
                qa_results.append(qa_result)
                
            except Exception as e:
                print(f"[ERROR] å¤„ç†é—®é¢˜å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                qa_result = {
                    "question_id": qi.get("question_id"),
                    "question": q,
                    "gold_answer": gold,
                    "question_type": question_type,
                    "question_date": question_date,
                    "answer_session_ids": answer_session_ids,
                    "error": str(e)
                }
                qa_results.append(qa_result)
        
        # ä¿å­˜ç»“æœ
        results_file = os.path.join(sample_results_dir, "qa_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(qa_results, f, ensure_ascii=False, indent=2)
        print(f"\n[OK] ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ä¿å­˜æ‰€æœ‰ç ”ç©¶è½¨è¿¹çš„æ±‡æ€»
        all_research_traces = []
        for i, qa_result in enumerate(qa_results, 1):
            if "research_trace_file" in qa_result:
                trace_file = qa_result["research_trace_file"]
                if os.path.exists(trace_file):
                    with open(trace_file, 'r', encoding='utf-8') as f:
                        trace_data = json.load(f)
                        all_research_traces.append({
                            "question_index": i,
                            "question_id": qa_result["question_id"],
                            "question": qa_result["question"],
                            "question_type": qa_result["question_type"],
                            "research_trace": trace_data
                        })
        
        if all_research_traces:
            traces_summary_file = os.path.join(sample_results_dir, "all_research_traces.json")
            with open(traces_summary_file, 'w', encoding='utf-8') as f:
                json.dump(all_research_traces, f, ensure_ascii=False, indent=2)
            print(f"[OK] æ‰€æœ‰ç ”ç©¶è½¨è¿¹æ±‡æ€»å·²ä¿å­˜åˆ°: {traces_summary_file}")
        
        # æ€»ç»“
        print(f"\n{'='*60}")
        print("å¤„ç†å®Œæˆç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"é—®é¢˜ID: {question_id}")
        print(f"ä¼šè¯æ•°: {len(session_chunks)}")
        print(f"è®°å¿†æ‘˜è¦æ•°: {len(final_state.abstracts)}")
        print(f"å¤„ç†é—®é¢˜æ•°: {len(qa_results)}")
        print(f"ç ”ç©¶è½¨è¿¹æ–‡ä»¶æ•°: {len(all_research_traces)}")
        print(f"ç»“æœä¿å­˜åˆ°: {sample_results_dir}")
        print(f"  - QAç»“æœ: qa_results.json")
        print(f"  - è®°å¿†çŠ¶æ€: memory_state.json")
        print(f"  - ç ”ç©¶è½¨è¿¹æ±‡æ€»: all_research_traces.json")
        print(f"  - å•ä¸ªç ”ç©¶è½¨è¿¹: research_trace_q*.json")
        
        return qa_results
        
    except Exception as e:
        error_msg = f"å¤„ç†æ ·æœ¬ {sample_index} æ—¶å‡ºé”™: {str(e)}"
        print(f"ERROR: {error_msg}")
        import traceback
        traceback.print_exc()
        return []


# ========== ä¸»å‡½æ•° ==========

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="GAM æ¡†æ¶ + LongMemEval æ•°æ®é›†æµ‹è¯•")
    parser.add_argument("--data", type=str, default="/share/project/bingyu/datasets/longmemeval/longmemeval_s_cleaned.json", 
                        help="LongMemEval æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--outdir", type=str, default="/share/project/bingyu/code/general-agentic-memory/results/longmemeval_output",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--start-idx", type=int, default=0, help="å¼€å§‹æ ·æœ¬ç´¢å¼•")
    parser.add_argument("--end-idx", type=int, default=5, help="ç»“æŸæ ·æœ¬ç´¢å¼•ï¼ˆä¸åŒ…å«ï¼‰ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰æ ·æœ¬")
    args = parser.parse_args()
    
    print("=" * 60)
    print("GAM æ¡†æ¶ + LongMemEval æ•°æ®é›†æµ‹è¯•")
    print("=" * 60)
    print(f"æ•°æ®é›†: {args.data}")
    print(f"è¾“å‡ºç›®å½•: {args.outdir}")
    print(f"æ ·æœ¬èŒƒå›´: {args.start_idx} åˆ° {args.end_idx-1 if args.end_idx else 'å…¨éƒ¨'} (å…± {args.end_idx - args.start_idx if args.end_idx else 'å…¨éƒ¨'} ä¸ªæ ·æœ¬)")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    samples = load_longmemeval(args.data)
    print(f"å…±åŠ è½½ {len(samples)} ä¸ªæ ·æœ¬")
    
    # é‡æ–°è®¾ç½®ç»“æŸç´¢å¼•ï¼ˆåœ¨åŠ è½½æ•°æ®åï¼‰
    if args.end_idx is None:
        args.end_idx = len(samples)
    
    print(f"å®é™…å¤„ç†èŒƒå›´: {args.start_idx} åˆ° {args.end_idx-1} (å…± {args.end_idx - args.start_idx} ä¸ªæ ·æœ¬)")
    
    # éªŒè¯ç´¢å¼•èŒƒå›´
    if args.start_idx < 0 or args.start_idx >= len(samples):
        print(f"é”™è¯¯: å¼€å§‹æ ·æœ¬ç´¢å¼• {args.start_idx} è¶…å‡ºèŒƒå›´ (æ€»æ ·æœ¬æ•°: {len(samples)})")
        return
    
    if args.end_idx > len(samples):
        print(f"è­¦å‘Š: ç»“æŸæ ·æœ¬ç´¢å¼• {args.end_idx} è¶…å‡ºèŒƒå›´ï¼Œè°ƒæ•´ä¸º {len(samples)}")
        args.end_idx = len(samples)
    
    if args.start_idx >= args.end_idx:
        print(f"é”™è¯¯: å¼€å§‹ç´¢å¼• {args.start_idx} å¿…é¡»å°äºç»“æŸç´¢å¼• {args.end_idx}")
        return
    
    # æ‰¹é‡å¤„ç†æ ·æœ¬
    all_results = []
    for sample_idx in range(args.start_idx, args.end_idx):
        sample = samples[sample_idx]
        print(f"\n{'='*80}")
        print(f"å¼€å§‹å¤„ç†æ ·æœ¬ {sample_idx}/{len(samples)-1} (èŒƒå›´: {args.start_idx}-{args.end_idx-1})")
        print(f"{'='*80}")
        
        try:
            results = process_sample(sample, sample_idx, args.outdir)
            all_results.extend(results)
            print(f"[OK] æ ·æœ¬ {sample_idx} å¤„ç†å®Œæˆ")
        except Exception as e:
            print(f"[ERROR] æ ·æœ¬ {sample_idx} å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ä¿å­˜æ‰€æœ‰ç»“æœæ±‡æ€»
    if all_results:
        summary_file = os.path.join(args.outdir, f"batch_results_{args.start_idx}_{args.end_idx-1}.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\n[OK] æ‰¹é‡ç»“æœæ±‡æ€»å·²ä¿å­˜: {summary_file}")
    
    print(f"\n{'='*60}")
    print("[OK] æ‰¹é‡æµ‹è¯•å®Œæˆï¼")
    print(f"å¤„ç†æ ·æœ¬æ•°: {args.end_idx - args.start_idx}")
    print(f"æˆåŠŸå¤„ç†: {len(all_results)} ä¸ªé—®é¢˜")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
